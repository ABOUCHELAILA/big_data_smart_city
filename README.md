# ğŸš¦ Pipeline Big Data Smart City - Analyse du Trafic Urbain

## ğŸ“‹ Vue d'ensemble

Ce projet implÃ©mente un pipeline Big Data End-to-End pour l'analyse du trafic urbain et de la mobilitÃ© intelligente dans le cadre des Smart Cities.

### ğŸ¯ Objectifs

- **Collecte** : Simuler des capteurs de trafic urbain en temps rÃ©el
- **Ingestion** : Streaming Apache Kafka pour donnÃ©es IoT
- **Stockage** : Data Lake HDFS avec organisation par zone/date
- **Orchestration** : Apache Airflow pour automatisation

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GÃ©nÃ©rateur   â”‚â”€â”€â”€â–¶â”‚     Kafka       â”‚â”€â”€â”€â–¶â”‚      HDFS      â”‚â”€â”€â”€â–¶â”‚   Airflow DAG   â”‚
â”‚   DonnÃ©es       â”‚    â”‚   (Streaming)   â”‚    â”‚   (Data Lake)   â”‚    â”‚  (Orchestration)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ PrÃ©requis

### Logiciels requis
- **Docker Desktop** (Windows/Mac) ou **Docker Engine** (Linux)
- **Docker Compose**
- **Git** (optionnel, pour cloner le projet)

### Configuration systÃ¨me recommandÃ©e
- **RAM** : 8GB minimum (16GB recommandÃ©)
- **CPU** : 4 cores minimum
- **Disque** : 10GB d'espace libre

---

## ğŸ“¦ Installation et DÃ©marrage

### 1. Cloner le projet
```bash
git clone <repository-url>
cd laila_big_data
```

### 2. DÃ©marrer l'infrastructure
```bash
# DÃ©marrer tous les services
docker-compose up -d

# VÃ©rifier que tous les conteneurs sont actifs
docker ps
```

### 3. Attendre l'initialisation (2-3 minutes)
Les services suivants dÃ©marrent :
- **Zookeeper** (port 2181)
- **Kafka** (port 29092)
- **Kafka UI** (port 8080)
- **HDFS NameNode** (port 9000, 9870)
- **HDFS DataNode** (port 9864, 9866)
- **PostgreSQL** (port 5432)
- **Airflow Webserver** (port 8081)
- **Airflow Scheduler**

### 4. AccÃ©der aux interfaces web
- **Airflow UI** : http://localhost:8081 (airflow/airflow)
- **Kafka UI** : http://localhost:8080
- **HDFS NameNode UI** : http://localhost:9870

---

## ğŸš€ Lancement Automatique

### Option 3 : Lancement terminal (Automatique)

#### Linux/Mac
```bash
# Rendre le script exÃ©cutable
chmod +x launch_pipeline.sh

# Lancer le pipeline automatiquement
./launch_pipeline.sh
```

#### Windows PowerShell
```powershell
# Lancer le pipeline automatiquement
.\launch_pipeline.ps1
```

#### Que fait le lancement automatique ?
1. **VÃ©rifie Docker** : DÃ©marre l'infrastructure si nÃ©cessaire
2. **Attend l'initialisation** : 60 secondes pour tous les services
3. **Lance le DAG** : Via API REST Airflow
4. **Retourne l'ID** : Pour suivre l'exÃ©cution
5. **Surveillance** : Liens vers Airflow UI et logs

#### Avantages du lancement automatique
- **Pas d'interface web** : Tout depuis le terminal
- **Scriptable** : IntÃ©grable dans d'autres automatisations
- **Rapide** : Un seule commande pour tout lancer
- **Monitoring** : ID d'exÃ©cution pour suivi

---

## ğŸ¯ Utilisation du Pipeline

### Option 1 : Via Airflow UI (RecommandÃ©)

1. **Ouvrir Airflow** : http://localhost:8081
2. **Se connecter** : airflow / airflow
3. **Activer le DAG** : `pipeline_complet_etapes_1_2`
4. **DÃ©clencher manuellement** : bouton "Trigger DAG"
5. **Surveiller l'exÃ©cution** : 3 tÃ¢ches sÃ©quentielles

### Option 2 : Lancement manuel (Tests)

#### GÃ©nÃ©ration de donnÃ©es
```bash
docker exec airflow-webserver bash -c "
cd /opt/airflow && 
python data_generator/traffic_data_generator.py --sensors 10 --events-per-second 2 --duration 30
"
```

#### Ingestion Kafka
```bash
docker exec airflow-webserver bash -c "
cd /opt/airflow && 
python kafka_producer/kafka_producer_simple.py --bootstrap-servers kafka:29092 --events-per-second 2 --duration 30
"
```

#### VÃ©rification Kafka
```bash
docker exec airflow-webserver bash -c "
cd /opt/airflow && 
python kafka_consumer/kafka_consumer_simple.py --bootstrap-servers kafka:29092 --max-messages 10 --timeout 20
"
```

#### Stockage HDFS
```bash
docker exec airflow-webserver bash -c "
cd /opt/airflow && 
python kafka_consumer/kafka_consumer_hdfs_rest.py --bootstrap-servers kafka:29092 --namenode-host namenode --namenode-port 9870 --batch-size 20 --timeout 30
"
```

---

## ğŸ“Š Structure des DonnÃ©es

### Format JSON des Ã©vÃ©nements
```json
{
  "sensor_id": "SENSOR_960",
  "road_id": "ROAD_428", 
  "road_type": "avenue",
  "zone": "Zone commerciale",
  "vehicle_count": 8,
  "average_speed": 78.4,
  "occupancy_rate": 0.376,
  "event_time": "2026-01-06 13:48:41"
}
```

### Organisation HDFS
```
/data/raw/traffic/
â”œâ”€â”€ Zone commerciale/
â”‚   â””â”€â”€ 2026/01/06/
â”‚       â”œâ”€â”€ traffic_events_20260106_155700.json
â”‚       â””â”€â”€ traffic_events_20260106_155701.json
â”œâ”€â”€ Zone industrielle/
â”‚   â””â”€â”€ 2026/01/06/
â”‚       â””â”€â”€ traffic_events_20260106_155701.json
â””â”€â”€ Quartier residentiel/
    â””â”€â”€ 2026/01/06/
        â””â”€â”€ traffic_events_20260106_142628.json
```

---

## ğŸ”§ Configuration

### ParamÃ¨tres du gÃ©nÃ©rateur
- `--sensors` : Nombre de capteurs (dÃ©faut: 10)
- `--events-per-second` : FrÃ©quence de gÃ©nÃ©ration (dÃ©faut: 2)
- `--duration` : DurÃ©e en secondes (dÃ©faut: 30)

### ParamÃ¨tres Kafka
- `--bootstrap-servers` : Serveurs Kafka (dÃ©faut: kafka:29092)
- `--max-messages` : Messages maximum Ã  consommer
- `--timeout` : Timeout en secondes

### ParamÃ¨tres HDFS
- `--namenode-host` : HDFS NameNode (dÃ©faut: namenode)
- `--namenode-port` : Port NameNode (dÃ©faut: 9870)
- `--batch-size` : Taille des batchs (dÃ©faut: 20)

---

## âš ï¸ Conflits de DÃ©pendances Potentiels

### ğŸ Python - Versions compatibles
Le projet est optimisÃ© pour **Python 3.8+** avec les dÃ©pendances suivantes :

```txt
kafka-python==2.0.2      # Compatible Python 3.8+
hdfs3==0.3.1           # Compatible Python 3.8+
python-dateutil==2.8.2    # Compatible Python 3.7+
pytz==2023.3             # Compatible Python 3.6+
```

### ğŸš¨ Conflits connus et solutions

#### 1. **Python 3.9+ et hdfs3**
```bash
# ProblÃ¨me : hdfs3==0.3.1 incompatible avec Python 3.9+
# Solution : Utiliser notre version REST (dÃ©jÃ  implÃ©mentÃ©e)
# Le projet utilise kafka_consumer_hdfs_rest.py qui ne dÃ©pend pas de hdfs3
```

#### 2. **Conflit de ports systÃ¨me**
```bash
# Ports utilisÃ©s par le projet :
8080  # Kafka UI
8081  # Airflow Webserver  
9000  # HDFS NameNode
9870  # HDFS NameNode Web UI
5432  # PostgreSQL

# VÃ©rifier les ports occupÃ©s :
netstat -an | grep :8081
netstat -an | grep :8080

# Solution si conflit : Modifier docker-compose.yml
ports:
  - "8082:8081"  # Changer Airflow vers 8082
```

#### 3. **Docker Desktop vs Docker Engine**
```bash
# Windows : Docker Desktop requis
# Linux : Docker Engine + Docker Compose
# macOS : Docker Desktop recommandÃ©

# VÃ©rifier l'installation :
docker --version
docker-compose --version
```

#### 4. **Ressources systÃ¨me insuffisantes**
```bash
# SymptÃ´mes : Conteneurs qui redÃ©marrent
# Solution : Augmenter les ressources Docker Desktop
# RAM : 8GB minimum (16GB recommandÃ©)
# CPU : 4 cores minimum
```

#### 5. **Conflits de dÃ©pendances locales**
```bash
# Si vous avez dÃ©jÃ  Kafka/Hadoop installÃ©s localement
# ProblÃ¨me : Ports et services en conflit
# Solution : ArrÃªter les services locaux ou utiliser diffÃ©rents ports

# ArrÃªter Kafka local :
systemctl stop kafka-server
systemctl stop zookeeper

# ArrÃªter Hadoop local :
stop-dfs.sh
stop-yarn.sh
```

### ğŸ”§ Solutions de contournement

#### Option 1 : Utiliser uniquement Docker (RecommandÃ©)
```bash
# Aucune installation locale requise
# Tout est dans les conteneurs Docker
# Pas de conflits de dÃ©pendances Python
```

#### Option 2 : Environnement virtuel
```bash
# CrÃ©er un environnement isolÃ©
python3.8 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

pip install -r requirements.txt
```

#### Option 3 : Modification des ports
```yaml
# Dans docker-compose.yml
services:
  airflow-webserver:
    ports:
      - "8082:8081"  # Ã‰viter le conflit
```

### âœ… VÃ©rification avant lancement
```bash
# 1. VÃ©rifier Docker
docker --version
docker-compose --version

# 2. VÃ©rifier les ports
netstat -an | grep -E ":(8080|8081|9000|5432)"

# 3. VÃ©rifier la RAM disponible
# Windows/Mac : VÃ©rifier Docker Desktop settings
# Linux : free -h

# 4. Lancer le projet
docker-compose up -d
```

---

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨mes courants

#### Port dÃ©jÃ  utilisÃ©
```bash
# VÃ©rifier les ports utilisÃ©s
netstat -an | grep :8081
netstat -an | grep :8080

# Tuer les processus si nÃ©cessaire
sudo kill -9 <PID>
```

#### Conteneurs ne dÃ©marrent pas
```bash
# VÃ©rifier les logs
docker-compose logs namenode
docker-compose logs kafka
docker-compose logs airflow-webserver

# RedÃ©marrer les services
docker-compose down
docker-compose up -d
```

#### Messages non reÃ§us dans HDFS
```bash
# VÃ©rifier le topic Kafka
docker exec kafka bash -c "kafka-topics --bootstrap-server localhost:29092 --list"

# VÃ©rifier les messages dans le topic
docker exec kafka bash -c "kafka-console-consumer --bootstrap-server localhost:29092 --topic traffic-events --from-beginning --max-messages 5"

# VÃ©rifier HDFS
docker exec namenode bash -c "hdfs dfs -ls -R /data/raw/traffic"
```

#### Airflow DAG n'apparaÃ®t pas
```bash
# RafraÃ®chir les DAGs Airflow
docker exec airflow-webserver bash -c "airflow dags report"

# RedÃ©marrer Airflow
docker-compose restart airflow-webserver airflow-scheduler
```

---

## ğŸ“ Structure du Projet

```
laila_big_data/
â”œâ”€â”€ docker-compose.yml              # Infrastructure Docker
â”œâ”€â”€ requirements.txt               # DÃ©pendances Python
â”œâ”€â”€ airflow_dags/
â”‚   â””â”€â”€ pipeline_complet_etapes_1_2.py  # DAG principal
â”œâ”€â”€ data_generator/
â”‚   â””â”€â”€ traffic_data_generator.py   # GÃ©nÃ©rateur de donnÃ©es
â”œâ”€â”€ kafka_producer/
â”‚   â””â”€â”€ kafka_producer_simple.py   # Producer Kafka
â”œâ”€â”€ kafka_consumer/
â”‚   â”œâ”€â”€ kafka_consumer_simple.py    # Consumer validation
â”‚   â””â”€â”€ kafka_consumer_hdfs_rest.py # Consumer HDFS
â”œâ”€â”€ analytics/                    # PrÃ©parÃ© pour analytics futures
â”œâ”€â”€ config/                      # Fichiers de configuration
â”œâ”€â”€ data/                        # DonnÃ©es locales de test
â”œâ”€â”€ logs/                        # Logs des applications
â””â”€â”€ scripts/                     # Scripts utilitaires
```

---

## ğŸš€ Personnalisation

### Ajouter de nouvelles zones
Modifier `data_generator/traffic_data_generator.py` :
```python
ZONES = [
    "Centre-ville",
    "PÃ©riphÃ©rie", 
    "Zone commerciale",
    "Zone industrielle",
    "Quartier residentiel",
    # Ajouter vos zones ici
]
```

### Modifier la frÃ©quence de gÃ©nÃ©ration
Dans le DAG `pipeline_complet_etapes_1_2.py` :
```python
'python data_generator/traffic_data_generator.py --sensors 15 --events-per-second 4 --duration 50'
```

### Changer la taille des batchs HDFS
```python
'python kafka_consumer/kafka_consumer_hdfs_rest.py --batch-size 50'
```

---

## ğŸ“ˆ Monitoring

### MÃ©triques disponibles
- **Kafka UI** : Messages par seconde, lag des consumers
- **Airflow UI** : DurÃ©e des tÃ¢ches, historique d'exÃ©cution
- **HDFS UI** : Espace disque utilisÃ©, nombre de fichiers

### Logs
```bash
# Logs Airflow
docker logs airflow-webserver -f
docker logs airflow-scheduler -f

# Logs Kafka
docker logs kafka -f

# Logs HDFS
docker logs namenode -f
docker logs datanode -f
```

---

## ğŸ¯ Prochaines Ã‰tapes (Extensions possibles)

### Ã‰tape 4 - Traitement des donnÃ©es
- **Apache Spark** : Traitement distribuÃ©
- **Nettoyage** : Validation et filtrage
- **AgrÃ©gation** : Statistiques par zone/pÃ©riode

### Ã‰tape 5 - Analytics
- **Tableaux de bord** : Grafana + Kibana
- **Alertes** : DÃ©tection de congestions
- **ML** : PrÃ©dictions de trafic

### Ã‰tape 6 - Production
- **SÃ©curitÃ©** : Authentication, encryption
- **ScalabilitÃ©** : Cluster multi-nÅ“uds
- **Monitoring** : Prometheus + AlertManager

---

## ğŸ“ Support

### Documentation technique
- **Apache Kafka** : https://kafka.apache.org/documentation/
- **Apache Hadoop HDFS** : https://hadoop.apache.org/docs/stable/
- **Apache Airflow** : https://airflow.apache.org/docs/

### Issues et contributions
- Signaler les problÃ¨mes via GitHub Issues
- Contribuer via Pull Requests

---

## ğŸ“œ Licence

Ce projet est sous licence MIT - voir fichier LICENSE pour dÃ©tails.

---

## ğŸ‘¥ Auteurs

Projet rÃ©alisÃ© dans le cadre du devoir Big Data - Smart City Traffic Analysis.

**Data Engineer** : Pipeline End-to-End pour l'analyse du trafic urbain intelligent.

---

*ğŸš¦ Made with â¤ï¸ for Smart Cities*
